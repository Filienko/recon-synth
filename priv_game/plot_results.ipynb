{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "# add latex\n",
    "import os\n",
    "os.environ[\"PATH\"] += os.pathsep + '/home/sundar/texlive/2022/bin/x86_64-linux'\n",
    "\n",
    "# Add directory above current directory to path\n",
    "import sys; sys.path.insert(0, '..')\n",
    "from load_data import *\n",
    "\n",
    "# graphing\n",
    "plt.rcParams.update({\n",
    "    'font.size': 14,\n",
    "    'text.usetex': True,\n",
    "    'text.latex.preamble': r'\\usepackage{libertine}\\usepackage[libertine]{newtxmath} \\usepackage{sfmath}',\n",
    "    'font.family': 'sans-serif',\n",
    "})\n",
    "\n",
    "reps = 500\n",
    "attack_colors = [\"#c159a1\", \"#6d392e\", \"#9b9c07\"]\n",
    "\n",
    "data_dir = 'results/'\n",
    "img_dir = f'{data_dir}/images'\n",
    "os.makedirs(img_dir, exist_ok=True)\n",
    "save_img = True\n",
    "\n",
    "colors = ['black', '#5bdb5f', '#0080ffff', '#f10800ff', '#ff9400ff', '#00e4f8ff']\n",
    "markers = ['+', '1', 6, '*', 'd', 's']\n",
    "# synth_models = ['NonPrivate', 'BayNet_3parents', 'RAP_2Kiters', 'CTGAN', 'IndHist']\n",
    "# synth_model_labels = ['NonPrivate', 'BayNet', 'RAP', 'CTGAN', 'IndHist']\n",
    "synth_models = ['NonPrivate']\n",
    "synth_model_labels = ['NonPrivate']\n",
    "\n",
    "synth_sizes = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "synth_size_labels = ['$10^1$', '$10^2$', '$10^3$', '$10^4$', '$10^5$', '$10^6$']\n",
    "\n",
    "# DP plots does not have 10^1\n",
    "dp_synth_indices = [1, 3, 5]\n",
    "dp_synth_size_labels = [synth_size_labels[i] for i in dp_synth_indices]\n",
    "\n",
    "data_names = ['acs', 'fire']\n",
    "data_labels = ['ACS', 'FIRE']\n",
    "\n",
    "def get_attack(attack_name):\n",
    "    if attack_name == 'recon':\n",
    "        return result_privacy[\n",
    "            (result_privacy['attack_name'] == 'recon') &\n",
    "            (result_privacy['k'] == 3) &\n",
    "            (result_privacy['scale_type'] == 'cond') &\n",
    "            (result_privacy['n_queries'] == -1)\n",
    "        ]\n",
    "    elif attack_name == 'dcr':\n",
    "        return result_privacy[\n",
    "            (result_privacy['attack_name'] == 'dcr') &\n",
    "            (result_privacy['k'] == 3) &\n",
    "            (result_privacy['n_queries'] == -1)\n",
    "        ]\n",
    "    elif attack_name == 'inference':\n",
    "        return result_privacy[\n",
    "            (result_privacy['attack_name'] == 'infer') &\n",
    "            (result_privacy['k'] == 3) &\n",
    "            (result_privacy['n_queries'] == -1)\n",
    "        ]\n",
    "\n",
    "result_privacy = pd.read_csv(f'{data_dir}/results_privacy.csv')\n",
    "result_utility = pd.read_csv(f'{data_dir}/results_utility.csv')\n",
    "result_utility = result_utility[result_utility['synth_size'].isin(synth_sizes)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot utility (Avg 3-TVD & mean relative error)\n",
    "tasks = [('avg_tvd', '3-TVD'), ('rel_mean', '$\\\\text{MRE}_{> 10}$')]\n",
    "fig, axs = plt.subplots(len(tasks), 2)\n",
    "first_label = True\n",
    "for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "    result_data = result_utility[result_utility['data_name'] == data_name]\n",
    "    for j, (task, task_label) in enumerate(tasks):\n",
    "        ax = axs.flat[2 * j + i]\n",
    "        for synth_model, color, synth_model_label in zip(synth_models, colors, synth_model_labels):\n",
    "            curr_result = result_data[result_data['synth_model'] == synth_model]\n",
    "            xs = curr_result['synth_size'].to_numpy()\n",
    "            ys = curr_result[task].to_numpy()\n",
    "            ax.plot(xs, ys, color=color, marker='o', label=synth_model_label if first_label else None)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('Synthetic data size ($m$)')\n",
    "        \n",
    "        if task == 'avg_tvd':\n",
    "            ax.set_ylim(0.0, 1.0)\n",
    "            ax.set_yticks(np.linspace(0.0, 1.0, 6))\n",
    "        elif task == 'rel_mean':\n",
    "            ax.set_ylim(0.0, 1.5)\n",
    "            ax.set_yticks(np.linspace(0.0, 1.5, 6))\n",
    "        elif task == 'f1_diff':\n",
    "            ax.set_ylim(0.0, 0.5)\n",
    "            ax.set_yticks(np.linspace(0.0, 0.5, 6))\n",
    "        ax.set_xticks(synth_sizes)\n",
    "        \n",
    "        ax.set_ylabel(f'Error ({task_label})')\n",
    "        ax.set_title(data_label)\n",
    "        \n",
    "        ax.set_aspect(1.0/ax.get_data_ratio(), adjustable='box')\n",
    "\n",
    "        first_label = False\n",
    "\n",
    "# axs.flat[1].legend(bbox_to_anchor=(1.575, 1.03125))\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.05))\n",
    "fig.set_size_inches(10, len(tasks) * 5)\n",
    "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/utility.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot privacy (only recon adversary)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "result_recon = get_attack('recon')\n",
    "\n",
    "first_label = True\n",
    "for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "    result_recon_data = result_recon[result_recon['data_name'] == data_name]\n",
    "    ax = axs.flat[i]\n",
    "    for synth_model, color, synth_model_label in zip(synth_models, colors, synth_model_labels):\n",
    "        curr_result = result_recon_data[result_recon_data['synth_model'] == synth_model]\n",
    "        ax.plot(curr_result['synth_size'].to_numpy(), curr_result['acc'].to_numpy() * 100, color=color, marker='o', label=synth_model_label if first_label else None)\n",
    "    ax.plot(curr_result['synth_size'].to_numpy(), np.ones(len(curr_result['synth_size'])) * 50, color='black', linestyle='--', label='Random baseline' if first_label else None)\n",
    "    ax.set_xscale('log')\n",
    "    ax.set_xticks(synth_sizes)\n",
    "    ax.set_xlabel('Synthetic data size ($m$)')\n",
    "    ax.set_ylim(43, 105)\n",
    "    ax.set_ylabel('Attack accuracy (\\%)')\n",
    "    ax.set_title(data_label)\n",
    "\n",
    "    ax.set_aspect(1.0/ax.get_data_ratio(), adjustable='box')\n",
    "\n",
    "    first_label = False\n",
    "\n",
    "# axs.flat[1].legend(bbox_to_anchor=(1, 1.03125))\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.15))\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_recon.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot privacy ROC (only recon adversary)\n",
    "fig, axs = plt.subplots(1, 2)\n",
    "synth_size = '1M'\n",
    "for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "    ax = axs.flat[i]\n",
    "    for synth_model, color, synth_model_label in zip(synth_models, colors, synth_model_labels):\n",
    "        y_true = []\n",
    "        y_score = []\n",
    "        for rep in range(reps):\n",
    "            rep_dir = f'{data_dir}/{data_name}/reps/rep_{rep}/'\n",
    "            user = int(np.genfromtxt(f'{rep_dir}/user.csv'))\n",
    "\n",
    "            df = pd.read_csv(f'{rep_dir}/df.csv.gz', compression='gzip')\n",
    "            sol = np.load(f'{rep_dir}/{synth_model}/{synth_size}/simple/3way_cond/sol_-1_recon.npz')['arr_0']\n",
    "\n",
    "            y_true.append(df.iloc[user, df.columns.get_loc(get_default_secret_bit(data_name))])\n",
    "            y_score.append(sol[user])\n",
    "\n",
    "        fpr, tpr, _ = roc_curve(y_true, y_score)\n",
    "        ax.plot(fpr, tpr, color=color, label=synth_model_label if i == 0 else '')\n",
    "    ax.plot(fpr, fpr, color='black', linestyle='--', label='Random baseline' if i == 0 else '')\n",
    "    ax.set_xlabel('False positive rate')\n",
    "    ax.set_xlim(0, 1)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.set_ylabel('True positive rate')\n",
    "    ax.set_title(data_label)\n",
    "\n",
    "    ax.set_aspect(1.0/ax.get_data_ratio(), adjustable='box')\n",
    "\n",
    "# axs.flat[1].legend(bbox_to_anchor=(0.5, 0.0), ncol=4)\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.15))\n",
    "\n",
    "fig.set_size_inches(10, 5)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_recon_roc.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot recon vs dcr vs inference for 1M\n",
    "def plot_recon_vs_dcr_vs_infer(synth_size, fig=None, axs=None, legend=True):\n",
    "    if fig is None or axs is None:\n",
    "        fig, axs = plt.subplots(1, 2)\n",
    "        axs = axs.flat\n",
    "    pos = np.arange(len(synth_models))\n",
    "    width = 1 / len(synth_models)\n",
    "\n",
    "    result_recon = get_attack('recon')\n",
    "    result_dcr = get_attack('dcr')\n",
    "    result_inference = get_attack('inference')\n",
    "\n",
    "    for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "        ax = axs[i]\n",
    "        result_recon_data = result_recon[result_recon['data_name'] == data_name]\n",
    "        result_dcr_data = result_dcr[result_dcr['data_name'] == data_name]\n",
    "        result_inference_data = result_inference[result_inference['data_name'] == data_name]\n",
    "        results = []\n",
    "        yerrs = []\n",
    "        for synth_model in synth_models:\n",
    "            ax = axs[i]\n",
    "            curr_results = []\n",
    "            curr_yerrs = []\n",
    "            for task, task_label in [('recon', '$\\\\textrm{Adv}_{recon}$'), ('dcr', '$\\\\textrm{Adv}_{dcr}$'), ('inference', '$\\\\textrm{Adv}_{infer}$')]:\n",
    "                if task == 'recon':\n",
    "                    curr_result = result_recon_data[result_recon_data['synth_model'] == synth_model]\n",
    "                elif task == 'dcr':\n",
    "                    curr_result = result_dcr_data[result_dcr_data['synth_model'] == synth_model]\n",
    "                else:\n",
    "                    curr_result = result_inference_data[result_inference_data['synth_model'] == synth_model]\n",
    "\n",
    "                if len(curr_result) == 0:\n",
    "                    curr_results.append(0)\n",
    "                    curr_yerrs.append(0)\n",
    "                else:\n",
    "                    curr_result = curr_result[curr_result['synth_size'] == synth_size]['acc'].to_numpy()[0]\n",
    "                    curr_results.append(curr_result)\n",
    "                    curr_yerrs.append(np.sqrt(curr_result * (1 - curr_result) / 500))\n",
    "                \n",
    "            results.append(curr_results)\n",
    "            yerrs.append(curr_yerrs)\n",
    "        results = np.array(results)\n",
    "        yerrs = np.array(yerrs)\n",
    "\n",
    "        for j, (task, task_label, color) in enumerate([('recon', '$\\\\textrm{Adv}_{recon}$', attack_colors[0]), ('dcr', '$\\\\textrm{Adv}_{dcr}$', attack_colors[1]), ('inference', '$\\\\textrm{Adv}_{infer}$', attack_colors[2])]):\n",
    "            ax.bar(pos + width * j, results[:, j] * 100, color=color, label=task_label, width=width, yerr=yerrs[:, j] * 100, capsize=2.5)\n",
    "        xlim_left, xlim_right = ax.get_xlim()\n",
    "        ax.plot([xlim_left, xlim_right], [50, 50], color='black', linestyle='--', label='Random baseline')\n",
    "        ax.set_ylim(43, 105)\n",
    "        ax.set_ylabel('Attack accuracy (\\%)')\n",
    "        ax.set_title(data_label)\n",
    "        ax.set_xticks(np.arange(len(synth_models)) + 0.185)\n",
    "        ax.set_xticklabels(synth_model_labels)\n",
    "\n",
    "    if legend:\n",
    "        axs[1].legend(bbox_to_anchor=(1.55, 1.03125))\n",
    "        fig.set_size_inches(12, 5)\n",
    "\n",
    "    return fig, axs\n",
    "\n",
    "fig, _ = plot_recon_vs_dcr_vs_infer(1000000)\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/recon_vs_dcr_vs_infer.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(len(synth_sizes), 2)\n",
    "for i, (synth_size, synth_size_label) in enumerate(zip(synth_sizes, synth_size_labels)):\n",
    "    curr_axs = (axs.flat[2 * i], axs.flat[2 * i + 1])\n",
    "    plot_recon_vs_dcr_vs_infer(synth_size, fig=fig, axs=curr_axs, legend=False)\n",
    "    curr_axs[0].set_title(f'ACS, Synthetic data size = {synth_size_label}')\n",
    "    curr_axs[1].set_title(f'FIRE, Synthetic data size = {synth_size_label}')\n",
    "\n",
    "axs.flat[1].legend(bbox_to_anchor=(1.45, 1.03125))\n",
    "fig.set_size_inches(15, len(synth_sizes) * 6)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/recon_vs_dcr_vs_infer_full.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_priv_util_tradeoff(combined_df, synth_models, synth_model_labels, synth_colors=colors):\n",
    "    combined_df = combined_df[(combined_df['synth_model'].isin(synth_models))]\n",
    "\n",
    "    tasks = [('avg_tvd', '3-TVD'), ('rel_mean', '$\\\\text{MRE}_{> 10}$')]\n",
    "\n",
    "    fig, axs = plt.subplots(len(tasks), 2)\n",
    "    for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "        combined_df_data = combined_df[combined_df['data_name'] == data_name]\n",
    "        for j, (task, task_label) in enumerate(tasks):\n",
    "            ax = axs.flat[2 * j + i]\n",
    "            for (synth_size, marker) in zip(synth_sizes, markers):\n",
    "                curr_df = combined_df_data[combined_df_data['synth_size'] == synth_size]\n",
    "\n",
    "                errs = []\n",
    "                accs = []\n",
    "                for synth_model in synth_models:\n",
    "                    curr_err = curr_df[curr_df['synth_model'] == synth_model][task]\n",
    "                    curr_acc = curr_df[curr_df['synth_model'] == synth_model][f'acc']\n",
    "                        \n",
    "                    errs.append(curr_err)\n",
    "                    accs.append(curr_acc)\n",
    "\n",
    "                for curr_err, curr_acc, synth_model_label, color in zip(errs, accs, synth_model_labels, synth_colors):\n",
    "                    ax.scatter(curr_err, curr_acc * 100, c=color, alpha=0.5, s=250, label=synth_model_label, marker=marker)\n",
    "\n",
    "            ax.set_xlabel(f'Error ({task_label})')\n",
    "            ax.set_ylabel('$\\\\text{Acc}_{max} (\\%)$')\n",
    "                \n",
    "            if task == 'avg_tvd':\n",
    "                ax.set_xlim(0, 1)\n",
    "                ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "\n",
    "                # plot good privacy line\n",
    "                ax.plot([0, 1], [60, 60], color='black', linestyle='--')\n",
    "            elif task == 'rel_mean':\n",
    "                ax.set_xlim(0, 1.6)\n",
    "                ax.set_xticks([0, 0.2, 0.4, 0.6, 0.8, 1.0, 1.2, 1.4, 1.6])\n",
    "\n",
    "                # plot good privacy line\n",
    "                ax.plot([0, 1.6], [60, 60], color='black', linestyle='--')\n",
    "            elif task == 'f1_diff':\n",
    "                ax.set_xlim(0.0, 0.5)\n",
    "                ax.set_xticks([0, 0.1, 0.2, 0.3, 0.4, 0.5])\n",
    "\n",
    "            ax.set_ylim(50, 100)\n",
    "            ax.set_yticks([50, 60, 70, 80, 90, 100])\n",
    "            ax.set_title(data_label)\n",
    "\n",
    "            if task != 'f1_diff':\n",
    "                # plot good utility line\n",
    "                ax.plot([0.2, 0.2], [50, 100], color='black', linestyle='--')\n",
    "\n",
    "    # axs.flat[1].legend(bbox_to_anchor=(1.55, 1.03125))\n",
    "    handles = []\n",
    "    for synth_model_label, color in zip(synth_model_labels, synth_colors):\n",
    "        handles.append(mlines.Line2D([], [], color=color, marker='.', linestyle='None',\n",
    "                            markersize=10, label=synth_model_label))\n",
    "\n",
    "    for synth_size_label, marker in zip(synth_size_labels, markers):\n",
    "        handles.append(mlines.Line2D([], [], color='black', marker=marker, linestyle='None',\n",
    "                            markersize=10, label=f'$m$ = {synth_size_label}'))\n",
    "        \n",
    "    if '$' in synth_model_labels[0]:\n",
    "        # DP\n",
    "        axs.flat[1].legend(handles=handles, bbox_to_anchor=(1.45, 1.03125))\n",
    "    else:\n",
    "        axs.flat[1].legend(handles=handles, bbox_to_anchor=(1, 1.03125))\n",
    "    fig.set_size_inches(10, len(tasks) * 5)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_recon = get_attack('recon')\n",
    "result_dcr = get_attack('dcr')\n",
    "result_inference = get_attack('inference')\n",
    "result_attack = pd.concat([result_recon, result_dcr, result_inference])\n",
    "result_attack = result_attack.groupby(['data_name', 'synth_model', 'synth_size']).max()\n",
    "\n",
    "combined_df = pd.merge(result_utility, result_attack, how='inner', on=['data_name', 'synth_model', 'synth_size'])\n",
    "\n",
    "fig = plot_priv_util_tradeoff(combined_df, synth_models, synth_model_labels)\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_utility_tradeoff.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_utility = pd.read_csv(f'{data_dir}/results_utility.csv')\n",
    "\n",
    "for attack in ['recon', 'dcr', 'inference']:\n",
    "    result_attack = get_attack(attack)\n",
    "\n",
    "    combined_df = pd.merge(result_utility, result_attack, how='inner', on=['data_name', 'synth_model', 'synth_size'])\n",
    "\n",
    "    fig = plot_priv_util_tradeoff(combined_df, synth_models, synth_model_labels)\n",
    "    if save_img:\n",
    "        fig.savefig(f'{img_dir}/privacy_utility_tradeoff_{attack}.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_vs_eps_dp(synth_model):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "    attacks = ('recon', '$\\\\textrm{Adv}_{recon}$'), ('dcr', '$\\\\textrm{Adv}_{dcr}$'), ('inference', '$\\\\textrm{Adv}_{infer}$')\n",
    "    # attacks = [('recon', '$\\\\textrm{Adv}_{recon}$'), ('dcr', '$\\\\textrm{Adv}_{dcr}$')]\n",
    "\n",
    "    if synth_model == 'RAP_2Kiters':\n",
    "        nondp_name = 'RAP_2Kiters'\n",
    "        dp_name = 'RAP_2Kiters'\n",
    "    elif synth_model == 'PrivBayes_3parents':\n",
    "        nondp_name = 'BayNet_3parents'\n",
    "        dp_name = 'PrivBayes_3parents'\n",
    "\n",
    "    epses = [1, 10, 100]\n",
    "    eps_labels = ['1', '10', '100']\n",
    "\n",
    "    pos = np.arange(len(epses))\n",
    "    width = 1 / (len(epses) + 1)\n",
    "\n",
    "    for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "        ax = axs.flat[i]\n",
    "        results = []\n",
    "        yerrs = []\n",
    "        for eps in epses:\n",
    "            curr_results = []\n",
    "            curr_yerrs = []\n",
    "            for (attack, _) in attacks:\n",
    "                attack_results = get_attack(attack)\n",
    "                if eps == 1000:\n",
    "                    curr_result = attack_results[(attack_results['data_name'] == data_name) & (attack_results['synth_model'] == nondp_name)]['acc'].to_numpy()[-1]\n",
    "                else:\n",
    "                    curr_result = attack_results[(attack_results['data_name'] == data_name) & (attack_results['synth_model'] == f'{dp_name}_{eps}eps')]['acc'].to_numpy()[-1]\n",
    "                yerr = np.sqrt(curr_result * (1 - curr_result) / 500)\n",
    "\n",
    "                curr_results.append(curr_result)\n",
    "                curr_yerrs.append(yerr)\n",
    "            results.append(curr_results)\n",
    "            yerrs.append(curr_yerrs)\n",
    "        results = np.array(results)\n",
    "        yerrs = np.array(yerrs)\n",
    "\n",
    "        for k, ((attack, attack_label), color) in enumerate(zip(attacks, attack_colors)):\n",
    "            ax.bar(pos + width * k, results[:, k] * 100, color=color, label=attack_label, width=width, yerr=yerrs[:, k] * 100, capsize=2.5)\n",
    "        xlim_left, xlim_right = ax.get_xlim()\n",
    "        ax.plot([xlim_left, xlim_right], [50, 50], color='black', linestyle='--', label='Random baseline')\n",
    "\n",
    "        ax.set_ylim(43, 105)\n",
    "        ax.set_ylabel('Attack accuracy (\\%)')\n",
    "        ax.set_title(data_label)\n",
    "        ax.set_xticks(np.arange(len(epses)) + 0.25)\n",
    "        ax.set_xticklabels(eps_labels)\n",
    "        ax.set_xlabel('Epsilon ($\\\\varepsilon$)')\n",
    "\n",
    "        ax.set_aspect(1.0/ax.get_data_ratio(), adjustable='box')\n",
    "\n",
    "    axs.flat[1].legend(bbox_to_anchor=(1.65, 1.03125))\n",
    "    fig.set_size_inches(10, 5)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs epsilon for RAP\n",
    "fig = plot_acc_vs_eps_dp('RAP_2Kiters')\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_all_dp_rapdp.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs epsilon for privbayes\n",
    "fig = plot_acc_vs_eps_dp('PrivBayes_3parents')\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_all_dp_privbayes.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_acc_vs_eps_dp(synth_model, attack_name):\n",
    "    fig, axs = plt.subplots(1, 2)\n",
    "\n",
    "    if synth_model == 'RAP_2Kiters':\n",
    "        nondp_name = 'RAP_2Kiters'\n",
    "        dp_name = 'RAP_2Kiters'\n",
    "    elif synth_model == 'PrivBayes_3parents':\n",
    "        nondp_name = 'BayNet_3parents'\n",
    "        dp_name = 'PrivBayes_3parents'\n",
    "\n",
    "    epses = [1, 10, 100]\n",
    "    eps_labels = ['1', '10', '100']\n",
    "    attack_results = get_attack(attack_name)\n",
    "\n",
    "    pos = np.arange(len(epses))\n",
    "    width = 1 / (len(epses) + 1)\n",
    "\n",
    "    for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "        ax = axs.flat[i]\n",
    "\n",
    "        results = []\n",
    "        yerrs = []\n",
    "        for eps in epses:\n",
    "            curr_results = []\n",
    "            curr_yerrs = []\n",
    "            for synth_index in dp_synth_indices:\n",
    "                if eps == 1000:\n",
    "                    curr_result = attack_results[(attack_results['data_name'] == data_name) & (attack_results['synth_model'] == nondp_name)]['acc'].to_numpy()[synth_index]\n",
    "                else:\n",
    "                    curr_result = attack_results[(attack_results['data_name'] == data_name) & (attack_results['synth_model'] == f'{dp_name}_{eps}eps')]['acc'].to_numpy()[synth_index]\n",
    "                yerr = np.sqrt(curr_result * (1 - curr_result) / 500)\n",
    "                \n",
    "                curr_results.append(curr_result)\n",
    "                curr_yerrs.append(yerr)\n",
    "            results.append(curr_results)\n",
    "            yerrs.append(curr_yerrs)\n",
    "        results = np.array(results)\n",
    "        yerrs = np.array(yerrs)\n",
    "\n",
    "        for k, (synth_index, color, synth_size_label) in enumerate(zip(dp_synth_indices, colors[1:], dp_synth_size_labels)):\n",
    "            ax.bar(pos + width * k, results[:, k] * 100, color=color, label=f'$m =$ {synth_size_label}', width=width, yerr=yerrs[:, k] * 100, capsize=2.5)\n",
    "        xlim_left, xlim_right = ax.get_xlim()\n",
    "        ax.plot([xlim_left, xlim_right], [50, 50], color='black', linestyle='--', label='Random baseline')\n",
    "\n",
    "        ax.set_ylim(43, 105)\n",
    "        ax.set_ylabel('Attack accuracy (\\%)')\n",
    "        ax.set_title(data_label)\n",
    "        ax.set_xticks(np.arange(len(epses)) + 0.25)\n",
    "        ax.set_xticklabels(eps_labels)\n",
    "        ax.set_xlabel('Epsilon ($\\\\varepsilon$)')\n",
    "\n",
    "    axs.flat[1].legend(bbox_to_anchor=(1.65, 1.03125))\n",
    "    fig.set_size_inches(10, 5)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs synth size for rapdp\n",
    "fig = plot_acc_vs_eps_dp('RAP_2Kiters', 'recon')\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_recon_dp_rapdp.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot accuracy vs synth size for privbayes\n",
    "fig = plot_acc_vs_eps_dp('PrivBayes_3parents', 'inference')\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_infer_dp_privbayes.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_util_vs_eps_dp(synth_model):\n",
    "    tasks = [('avg_tvd', '3-TVD'), ('rel_mean', '$\\\\text{MRE}_{>10}$')]\n",
    "\n",
    "    if synth_model == 'RAP_2Kiters':\n",
    "        nondp_name = 'RAP_2Kiters'\n",
    "        dp_name = 'RAP_2Kiters'\n",
    "    elif synth_model == 'PrivBayes_3parents':\n",
    "        nondp_name = 'BayNet_3parents'\n",
    "        dp_name = 'PrivBayes_3parents'\n",
    "    \n",
    "    epses = [1, 10, 100]\n",
    "    eps_labels = ['1', '10', '100']\n",
    "\n",
    "    pos = np.arange(len(epses))\n",
    "    width = 1 / (len(epses) + 1)\n",
    "\n",
    "    curr_synth_models = []\n",
    "    for eps in epses:\n",
    "        if eps == 1000:\n",
    "            curr_synth_models.append(nondp_name)\n",
    "        else:\n",
    "            curr_synth_models.append(f'{dp_name}_{eps}eps')\n",
    "\n",
    "    fig, axs = plt.subplots(len(tasks), 2)\n",
    "    for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "        result_data = result_utility[result_utility['data_name'] == data_name]\n",
    "        for j, (task, task_label) in enumerate(tasks):\n",
    "            ax = axs.flat[2 * j + i]\n",
    "\n",
    "            results = []\n",
    "            yerrs = []\n",
    "            for synth_model in curr_synth_models:\n",
    "                curr_results = []\n",
    "                curr_yerrs = []\n",
    "                for synth_index in dp_synth_indices:\n",
    "                    curr_result_data = result_data[result_data['synth_model'] == synth_model]\n",
    "                    curr_result = curr_result_data[task].to_numpy()[synth_index]\n",
    "                    yerr = curr_result_data[f'{task}_std'].to_numpy()[synth_index]\n",
    "\n",
    "                    curr_results.append(curr_result)\n",
    "                    curr_yerrs.append(yerr)\n",
    "                results.append(curr_results)\n",
    "                yerrs.append(curr_yerrs)\n",
    "\n",
    "            results = np.array(results)\n",
    "            yerrs = np.array(yerrs)\n",
    "\n",
    "            for k, (synth_index, color, synth_size_label) in enumerate(zip(dp_synth_indices, colors[1:], dp_synth_size_labels)):\n",
    "                ax.bar(pos + width * k, results[:, k], color=color, label=f'$m =$ {synth_size_label}', width=width, yerr=yerrs[:, k], capsize=2.5)\n",
    "\n",
    "            if task == 'avg_tvd':\n",
    "                ax.set_ylim(0.0, 1.0)\n",
    "                ax.set_yticks(np.linspace(0.0, 1.0, 6))\n",
    "            elif task == 'rel_mean':\n",
    "                ax.set_ylim(0.0, 1.5)\n",
    "                ax.set_yticks(np.linspace(0.0, 1.5, 6))\n",
    "            elif task == 'f1_diff':\n",
    "                ax.set_ylim(0.0, 0.5)\n",
    "                ax.set_yticks(np.linspace(0.0, 0.5, 6))\n",
    "            ax.set_ylabel(f'Error ({task_label})')\n",
    "            ax.set_title(data_label)\n",
    "            ax.set_xticks(np.arange(len(epses)) + 0.25)\n",
    "            ax.set_xticklabels(eps_labels)\n",
    "            ax.set_xlabel('Epsilon ($\\\\varepsilon$)')\n",
    "\n",
    "    axs.flat[1].legend(bbox_to_anchor=(1.45, 1.03125))\n",
    "    fig.set_size_inches(10, len(tasks) * 5)\n",
    "    plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot utility against epsilon (Avg 3-TVD & 75th percentile relative error) for RAP\n",
    "fig = plot_util_vs_eps_dp('RAP_2Kiters')\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/utility_dp_rapdp.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot utility against epsilon (Avg 3-TVD & 75th percentile relative error) for privbayes\n",
    "fig = plot_util_vs_eps_dp('PrivBayes_3parents')\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/utility_dp_privbayes.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_priv_util_tradeoff_dp(synth_model):\n",
    "    if synth_model == 'RAP_2Kiters':\n",
    "        nondp_name = 'RAP_2Kiters'\n",
    "        dp_name = 'RAP_2Kiters'\n",
    "    elif synth_model == 'PrivBayes_3parents':\n",
    "        nondp_name = 'BayNet_3parents'\n",
    "        dp_name = 'PrivBayes_3parents'\n",
    "        \n",
    "    result_recon = get_attack('recon')\n",
    "    result_dcr = get_attack('dcr')\n",
    "    result_inference = get_attack('inference')\n",
    "    result_attack = pd.concat([result_recon, result_dcr, result_inference])\n",
    "    result_attack = result_attack.groupby(['data_name', 'synth_model', 'synth_size']).max()\n",
    "\n",
    "    eps_labels = ['1', '10', '100']\n",
    "    curr_synth_models = []\n",
    "    for eps in [1, 10, 100]:\n",
    "        curr_synth_models.append(f'{dp_name}_{eps}eps')\n",
    "    # curr_synth_models.append(nondp_name)\n",
    "    curr_synth_model_labels = [f'$\\\\varepsilon = {eps}$' for eps in eps_labels]\n",
    "\n",
    "    # curr_synth_model_labels[-1] = f'{curr_synth_model_labels[-1]} ({synth_model_label})'\n",
    "\n",
    "    combined_df = pd.merge(result_utility, result_attack, how='inner', on=['data_name', 'synth_model', 'synth_size'])\n",
    "\n",
    "    if 'BayNet' in nondp_name:\n",
    "        curr_colors = [attack_colors[0], attack_colors[1], attack_colors[2], colors[1]]\n",
    "    elif 'RAP' in nondp_name:\n",
    "        curr_colors = [attack_colors[0], attack_colors[1], attack_colors[2], colors[2]]\n",
    "\n",
    "    fig = plot_priv_util_tradeoff(combined_df, curr_synth_models, curr_synth_model_labels, synth_colors=curr_colors)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_priv_util_tradeoff_dp('RAP_2Kiters')\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_utility_tradeoff_dp_rapdp.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_priv_util_tradeoff_dp('PrivBayes_3parents')\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/privacy_utility_tradeoff_dp_privbayes.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_synth_models = synth_models[:-2] # drop CTGAN and IndHist\n",
    "curr_synth_model_labels = synth_model_labels[:-2] # drop CTGAN and IndHist\n",
    "# curr_synth_models, curr_synth_model_labels = synth_models, synth_model_labels\n",
    "curr_data_names = data_names[1:] # drop ACS\n",
    "curr_data_labels = data_labels[1:] # drop ACS\n",
    "\n",
    "fig, axs = plt.subplots(len(curr_data_names), len(curr_synth_models))\n",
    "\n",
    "results = result_privacy[\n",
    "    (result_privacy['attack_name'] == 'recon') &\n",
    "    (result_privacy['k'] == 3) &\n",
    "    (result_privacy['n_queries'] == -1)\n",
    "]\n",
    "\n",
    "first_label = True\n",
    "for j, (data_name, data_label) in enumerate(zip(curr_data_names, curr_data_labels)):\n",
    "    for i, (synth_model, synth_model_label) in enumerate(zip(curr_synth_models, curr_synth_model_labels)):\n",
    "        ax = axs.flat[j * len(curr_synth_models) + i]\n",
    "\n",
    "        curr_results = results[(results['data_name'] == data_name) & (results['synth_model'] == synth_model)]\n",
    "        mar_results = curr_results[curr_results['scale_type'] == 'normal']['acc'].to_numpy()\n",
    "        cond_results = curr_results[curr_results['scale_type'] == 'cond']['acc'].to_numpy()\n",
    "\n",
    "        ax.errorbar(synth_sizes, mar_results * 100, color=attack_colors[0], marker='o', label='Marginal queries' if first_label else None, yerr=np.sqrt(1 / 500 * mar_results * (1 - mar_results)) * 100, capsize=4, ecolor=attack_colors[0])\n",
    "        ax.errorbar(synth_sizes, cond_results * 100, color=attack_colors[1], marker='o', label='Conditional queries' if first_label else None, yerr=np.sqrt(1 / 500 * cond_results * (1 - cond_results)) * 100, capsize=4, ecolor=attack_colors[1])\n",
    "\n",
    "        ax.plot(synth_sizes, np.ones(len(synth_sizes)) * 50, color='black', linestyle='--', label='Random baseline' if first_label else None)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('Synthetic data size ($m$)')\n",
    "        ax.set_xticks(synth_sizes)\n",
    "        ax.set_ylim(43, 105)\n",
    "        ax.set_yticks(np.linspace(50, 100, 6))\n",
    "        ax.set_ylabel(f'{data_label}\\nAttack accuracy (\\%)')\n",
    "        if j == 0:\n",
    "            ax.set_title(synth_model_label)\n",
    "\n",
    "        ax.label_outer()\n",
    "        first_label = False\n",
    "\n",
    "# axs.flat[len(curr_synth_models) - 1].legend(bbox_to_anchor=(1.9, 1.03125))\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.2))\n",
    "fig.set_size_inches(len(curr_synth_models) * 4, len(curr_data_labels) * 4)\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/cond_vs_mar_min.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_synth_models = synth_models[:-2] # drop CTGAN and IndHist\n",
    "curr_synth_model_labels = synth_model_labels[:-2] # drop CTGAN and IndHist\n",
    "# curr_synth_models, curr_synth_model_labels = synth_models, synth_model_labels\n",
    "curr_colors = ['black', attack_colors[0], attack_colors[1], attack_colors[2]]\n",
    "\n",
    "fig, axs = plt.subplots(len(curr_synth_models), len(data_names))\n",
    "\n",
    "results = result_privacy[\n",
    "    (result_privacy['attack_name'] == 'recon') &\n",
    "    (result_privacy['k'] == 3) &\n",
    "    (result_privacy['n_queries'] == -1)\n",
    "]\n",
    "\n",
    "first_label = True\n",
    "for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "    for j, (synth_model, synth_model_label) in enumerate(zip(curr_synth_models, curr_synth_model_labels)):\n",
    "        ax = axs.flat[j * len(data_names) + i]\n",
    "\n",
    "        curr_results = results[(results['data_name'] == data_name) & (results['synth_model'] == synth_model)]\n",
    "        mar_results = curr_results[curr_results['scale_type'] == 'normal']['acc'].to_numpy()\n",
    "        cond_results = curr_results[curr_results['scale_type'] == 'cond']['acc'].to_numpy()\n",
    "\n",
    "        ax.errorbar(synth_sizes, mar_results * 100, color=attack_colors[0], marker='o', label='Marginal queries' if first_label else None, yerr=np.sqrt(1 / 500 * mar_results * (1 - mar_results)) * 100, capsize=4, ecolor=attack_colors[0])\n",
    "        ax.errorbar(synth_sizes, cond_results * 100, color=attack_colors[1], marker='o', label='Conditional queries' if first_label else None, yerr=np.sqrt(1 / 500 * cond_results * (1 - cond_results)) * 100, capsize=4, ecolor=attack_colors[1])\n",
    "\n",
    "        ax.plot(synth_sizes, np.ones(len(synth_sizes)) * 50, color='black', linestyle='--', label='Random baseline' if first_label else None)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('Synthetic data size ($m$)')\n",
    "        ax.set_xticks(synth_sizes)\n",
    "        ax.set_ylim(43, 105)\n",
    "        ax.set_yticks(np.linspace(50, 100, 6))\n",
    "        ax.set_ylabel(f'{synth_model_label}\\nAttack accuracy (\\%)')\n",
    "        if j == 0:\n",
    "            ax.set_title(data_label)\n",
    "\n",
    "        ax.label_outer()\n",
    "        first_label = False\n",
    "\n",
    "# axs.flat[len(curr_synth_models) - 1].legend(bbox_to_anchor=(1.9, 1.03125))\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, 0.05))\n",
    "fig.set_size_inches(len(data_names) * 4, len(curr_synth_models) * 4)\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/cond_vs_mar_all.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_synth_models = synth_models[:-2] # drop CTGAN and IndHist\n",
    "curr_synth_model_labels = synth_model_labels[:-2] # drop CTGAN and IndHist\n",
    "# curr_synth_models, curr_synth_model_labels = synth_models, synth_model_labels\n",
    "curr_colors = ['black', attack_colors[0], attack_colors[1], attack_colors[2]]\n",
    "\n",
    "fig, axs = plt.subplots(len(curr_synth_models), len(data_names))\n",
    "\n",
    "results = result_privacy[\n",
    "    (result_privacy['attack_name'] == 'recon') &\n",
    "    (result_privacy['scale_type'] == 'cond')\n",
    "]\n",
    "ks = [2, 3, 4, 234]\n",
    "k_labels = ['All 2-way', 'All 3-way', '100K 4-way', '2 + 3 + 4-way']\n",
    "curr_colors = ['black', attack_colors[0], attack_colors[1], attack_colors[2]]\n",
    "\n",
    "first_label = True\n",
    "for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "    for j, (synth_model, synth_model_label) in enumerate(zip(curr_synth_models, curr_synth_model_labels)):\n",
    "        ax = axs.flat[j * len(data_names) + i]\n",
    "\n",
    "        curr_results = results[(results['data_name'] == data_name) & (results['synth_model'] == synth_model)]\n",
    "        for k, k_label, color in zip(ks, k_labels, curr_colors):\n",
    "            if k == 2 or k == 3:\n",
    "                curr_results = curr_results[curr_results['n_queries'] == -1]\n",
    "            k_results = curr_results[curr_results['k'] == k]['acc'].to_numpy()\n",
    "\n",
    "            ax.errorbar(synth_sizes, k_results * 100, color=color, marker='o', label=f'{k_label} queries' if first_label else None, yerr=np.sqrt(1 / 500 * k_results * (1 - k_results)) * 100, capsize=4, ecolor=color)\n",
    "\n",
    "        ax.plot(synth_sizes, np.ones(len(synth_sizes)) * 50, color='black', linestyle='--', label='Random baseline' if first_label else None)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('Synthetic data size ($m$)')\n",
    "        ax.set_xticks(synth_sizes)\n",
    "        ax.set_ylim(43, 105)\n",
    "        ax.set_yticks(np.linspace(50, 100, 6))\n",
    "        ax.set_ylabel(f'{synth_model_label}\\nAttack accuracy (\\%)')\n",
    "        if j == 0:\n",
    "            ax.set_title(data_label)\n",
    "\n",
    "        ax.label_outer()\n",
    "        first_label = False\n",
    "\n",
    "# axs.flat[len(curr_synth_models) - 1].legend(bbox_to_anchor=(2.0, 1.03125))\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, 0.025))\n",
    "fig.set_size_inches(len(data_names) * 4, len(curr_synth_models) * 4)\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/2_vs_3_vs_4way.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "reps = 500\n",
    "\n",
    "avg_n_queries = {\n",
    "    'acs': {\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 100000,\n",
    "        234: 0\n",
    "    },\n",
    "    'fire': {\n",
    "        2: 0,\n",
    "        3: 0,\n",
    "        4: 100000,\n",
    "        234: 0\n",
    "    },\n",
    "}\n",
    "\n",
    "for data_name in ['acs', 'fire']:\n",
    "    for k in [2, 3]:\n",
    "        for rep in tqdm(range(reps)):\n",
    "            query_results = np.load(f'{data_dir}/{data_name}/reps/rep_{rep}/queries/simple/{k}way/result.npz')\n",
    "            n_queries = len(query_results) // 2\n",
    "            avg_n_queries[data_name][k] += n_queries / reps\n",
    "    \n",
    "    avg_n_queries[data_name][234] = avg_n_queries[data_name][2] + avg_n_queries[data_name][3] + avg_n_queries[data_name][4]\n",
    "\n",
    "avg_n_queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_synth_models = synth_models[:-2] # drop CTGAN and IndHist\n",
    "curr_synth_model_labels = synth_model_labels[:-2] # drop CTGAN and IndHist\n",
    "# curr_synth_models, curr_synth_model_labels = synth_models, synth_model_labels\n",
    "curr_colors = ['black', attack_colors[0], attack_colors[1], attack_colors[2]]\n",
    "curr_data_names = data_names[1:] # drop ACS\n",
    "curr_data_labels = data_labels[1:] # drop ACS\n",
    "\n",
    "fig, axs = plt.subplots(len(curr_data_names), len(curr_synth_models))\n",
    "\n",
    "results = result_privacy[\n",
    "    (result_privacy['attack_name'] == 'recon') &\n",
    "    (result_privacy['scale_type'] == 'cond')\n",
    "]\n",
    "\n",
    "n_queriess = [10, 100, 1000, 10000, 100000, -1]\n",
    "synth_size = 1000000\n",
    "\n",
    "first_label = True\n",
    "for j, (data_name, data_label) in enumerate(zip(curr_data_names, curr_data_labels)):\n",
    "    for i, (synth_model, synth_model_label) in enumerate(zip(curr_synth_models, curr_synth_model_labels)):\n",
    "        ax = axs.flat[j * len(curr_synth_models) + i]\n",
    "\n",
    "        ks = [2, 3, 4]\n",
    "        k_labels = ['All 2-way', 'All 3-way', '100K 4-way']\n",
    "        k, k_label, color = ks[1], k_labels[1], curr_colors[1]\n",
    "        curr_results = results[\n",
    "            (results['data_name'] == data_name) &\n",
    "            (results['synth_model'] == synth_model) &\n",
    "            (results['synth_size'] == synth_size) &\n",
    "            (results['k'] == k) &\n",
    "            (results['n_queries'].isin(n_queriess))\n",
    "        ]\n",
    "\n",
    "        curr_n_queries, curr_accs = [], []\n",
    "        for n_queries in n_queriess:\n",
    "            if n_queries >= avg_n_queries[data_name][k]:\n",
    "                continue\n",
    "\n",
    "            if n_queries == -1:\n",
    "                curr_n_queries.append(avg_n_queries[data_name][k])\n",
    "            else:\n",
    "                curr_n_queries.append(n_queries)\n",
    "\n",
    "            curr_accs.append(curr_results[curr_results['n_queries'] == n_queries]['acc'].to_numpy()[0])\n",
    "\n",
    "        ax.plot(curr_n_queries, np.array(curr_accs) * 100, color=color, marker='o', label=k_label if first_label else None)\n",
    "\n",
    "        ax.plot(curr_n_queries, np.ones(len(curr_n_queries)) * 50, color='black', linestyle='--', label='Random baseline' if first_label else None)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('\\# queries')\n",
    "        ax.set_xticks([10, 100, 1000, 10000])\n",
    "        ax.set_ylim(43, 105)\n",
    "        ax.set_yticks(np.linspace(50, 100, 6))\n",
    "        ax.set_ylabel(data_label)\n",
    "        if j == 0:\n",
    "            ax.set_title(f'{synth_model_label}\\nAttack accuracy (\\%)')\n",
    "        ax.label_outer()\n",
    "\n",
    "        first_label = False\n",
    "\n",
    "# axs.flat[len(curr_synth_models) - 1].legend(bbox_to_anchor=(1.7, 1.03125))\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, -0.2))\n",
    "fig.set_size_inches(len(curr_synth_models) * 4, len(curr_data_names) * 4)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/acc_vs_n_queries_min.pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_synth_models = synth_models[:-2] # drop CTGAN and IndHist\n",
    "curr_synth_model_labels = synth_model_labels[:-2] # drop CTGAN and IndHist\n",
    "# curr_synth_models, curr_synth_model_labels = synth_models, synth_model_labels\n",
    "curr_colors = ['black', attack_colors[0], attack_colors[1], attack_colors[2]]\n",
    "\n",
    "fig, axs = plt.subplots(len(curr_synth_models), len(data_names))\n",
    "\n",
    "results = result_privacy[\n",
    "    (result_privacy['solver'] == 'recon') &\n",
    "    (result_privacy['scale_type'] == 'cond')\n",
    "]\n",
    "\n",
    "n_queriess = [10, 100, 1000, 10000, 100000, -1]\n",
    "synth_size = 1000000\n",
    "\n",
    "first_label = True\n",
    "for i, (data_name, data_label) in enumerate(zip(data_names, data_labels)):\n",
    "    for j, (synth_model, synth_model_label) in enumerate(zip(curr_synth_models, curr_synth_model_labels)):\n",
    "        ax = axs.flat[j * len(data_names) + i]\n",
    "\n",
    "        ks = [2, 3, 4]\n",
    "        k_labels = ['All 2-way', 'All 3-way', '100K 4-way']\n",
    "        for k, k_label, color in zip(ks, k_labels, curr_colors):\n",
    "            curr_results = results[\n",
    "                (results['data_name'] == data_name) &\n",
    "                (results['synth_model'] == synth_model) &\n",
    "                (results['synth_size'] == synth_size) &\n",
    "                (results['k'] == k) &\n",
    "                (results['n_queries'].isin(n_queriess))\n",
    "            ]\n",
    "\n",
    "            curr_n_queries, curr_accs = [], []\n",
    "            for n_queries in n_queriess:\n",
    "                if n_queries >= avg_n_queries[data_name][k]:\n",
    "                    continue\n",
    "\n",
    "                if n_queries == -1:\n",
    "                    curr_n_queries.append(avg_n_queries[data_name][k])\n",
    "                else:\n",
    "                    curr_n_queries.append(n_queries)\n",
    "\n",
    "                curr_accs.append(curr_results[curr_results['n_queries'] == n_queries]['acc'].to_numpy()[0])\n",
    "\n",
    "            ax.plot(curr_n_queries, np.array(curr_accs) * 100, color=color, marker='o', label=k_label if first_label else None)\n",
    "\n",
    "        ax.plot(curr_n_queries, np.ones(len(curr_n_queries)) * 50, color='black', linestyle='--', label='Random baseline' if first_label else None)\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_xlabel('\\# queries')\n",
    "        ax.set_xticks([10, 100, 1000, 10000, 100000])\n",
    "        ax.set_ylim(43, 105)\n",
    "        ax.set_yticks(np.linspace(50, 100, 6))\n",
    "        ax.set_ylabel(f'{synth_model_label}\\nAttack accuracy (\\%)')\n",
    "        if j == 0:\n",
    "            ax.set_title(data_label)\n",
    "        ax.label_outer()\n",
    "\n",
    "        first_label = False\n",
    "\n",
    "# axs.flat[len(curr_synth_models) - 1].legend(bbox_to_anchor=(1.7, 1.03125))\n",
    "fig.legend(loc='lower center', ncol=3, bbox_to_anchor=(0.5, 0.025))\n",
    "fig.set_size_inches(len(data_names) * 4, len(curr_synth_models) * 4)\n",
    "\n",
    "if save_img:\n",
    "    fig.savefig(f'{img_dir}/acc_vs_n_queries.pdf', bbox_inches='tight')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reported Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6.1: AUCs\n",
    "results = get_attack('recon')\n",
    "results[(results['synth_size'] == 1000000) & (results['synth_model'].isin(synth_models))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6.2: Comparison to prior attacks\n",
    "cols = ['data_name', 'synth_model', 'synth_size', 'acc']\n",
    "results_recon = get_attack('recon')\n",
    "results_recon = results_recon[(results_recon['synth_size'] == 1000000) & (results_recon['synth_model'] == 'RAP_2Kiters')][cols]\n",
    "\n",
    "results_dcr = get_attack('dcr')\n",
    "results_dcr = results_dcr[(results_dcr['synth_size'] == 1000000) & (results_dcr['synth_model'] == 'RAP_2Kiters')][cols]\n",
    "\n",
    "results_infer = get_attack('inference')\n",
    "results_infer = results_infer[(results_infer['synth_size'] == 1000000) & (results_infer['synth_model'] == 'RAP_2Kiters')][cols]\n",
    "\n",
    "results = results_recon.merge(results_dcr, how='inner', on=['data_name', 'synth_model', 'synth_size'], suffixes=['_recon', '_dcr'])\n",
    "results = results.merge(results_infer, how='inner', on=['data_name', 'synth_model', 'synth_size']).rename({'acc': 'acc_infer'}, axis='columns')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6.3: Impact of synth data size\n",
    "results = get_attack('recon')\n",
    "results[(results['synth_size'].isin([100, 1000, 1000000])) & (results['synth_model'].isin(['RAP_2Kiters', 'BayNet_3parents']))].sort_values(['synth_model', 'data_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6.4: Calculate tradeoff accs\n",
    "df_privacy = pd.read_csv(f'{data_dir}/results_privacy.csv')\n",
    "df_privacy = df_privacy[((df_privacy['k'] == 3) & (df_privacy['n_queries'] == -1) & (df_privacy['scale_type'] == 'cond')) | (df_privacy['attack_name'] == 'dcr') | (df_privacy['attack_name'] == 'infer')]\n",
    "df_privacy = df_privacy.groupby(['data_name', 'synth_model', 'synth_size'], as_index=False).min()[['data_name', 'synth_model', 'synth_size', 'acc']]\n",
    "\n",
    "df_utility = pd.read_csv(f'{data_dir}/results_utility.csv')\n",
    "\n",
    "def get_min_amax(data_name, synth_model):\n",
    "    curr_df = df_utility[\n",
    "        (df_utility['data_name'] == data_name) &\n",
    "        (df_utility['synth_model'] == synth_model) &\n",
    "        (df_utility['avg_tvd'] < 0.2) &\n",
    "        (df_utility['rel_mean'] < 0.2)\n",
    "    ]\n",
    "\n",
    "    curr_df = curr_df.merge(df_privacy, on=['data_name', 'synth_model', 'synth_size'])\n",
    "    min_record = curr_df[curr_df['acc'] == curr_df['acc'].min()]\n",
    "    return min_record[['data_name', 'synth_model', 'synth_size', 'avg_tvd', 'rel_mean', 'acc']]\n",
    "\n",
    "def get_min_err(data_name, synth_model, err):\n",
    "    curr_df = df_privacy[\n",
    "        (df_privacy['data_name'] == data_name) &\n",
    "        (df_privacy['synth_model'] == synth_model) &\n",
    "        (df_privacy['acc'] < 0.6)\n",
    "    ]\n",
    "\n",
    "    curr_df = curr_df.merge(df_utility, on=['data_name', 'synth_model', 'synth_size'])\n",
    "    min_record = curr_df[curr_df[err] == curr_df[err].min()]\n",
    "    return min_record[['data_name', 'synth_model', 'synth_size', 'avg_tvd', 'rel_mean', 'acc']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_amax('acs', 'BayNet_3parents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_amax('acs', 'RAP_2Kiters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_amax('fire', 'BayNet_3parents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_amax('fire', 'RAP_2Kiters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_err('acs', 'CTGAN', 'rel_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_err('acs', 'BayNet_3parents', 'rel_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_err('acs', 'RAP_2Kiters', 'rel_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_err('fire', 'CTGAN', 'rel_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_err('fire', 'BayNet_3parents', 'rel_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_min_err('fire', 'RAP_2Kiters', 'rel_mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6.5: Impact of DP\n",
    "cols = ['data_name', 'synth_model', 'synth_size', 'acc']\n",
    "curr_synth_models = ['RAP_2Kiters', 'RAP_2Kiters_10eps']\n",
    "results_recon = get_attack('recon')\n",
    "results_recon = results_recon[(results_recon['synth_size'] == 1000000) & (results_recon['synth_model'].isin(curr_synth_models))][cols]\n",
    "\n",
    "results_dcr = get_attack('dcr')\n",
    "results_dcr = results_dcr[(results_dcr['synth_size'] == 1000000) & (results_dcr['synth_model'].isin(curr_synth_models))][cols]\n",
    "\n",
    "results_infer = get_attack('inference')\n",
    "results_infer = results_infer[(results_infer['synth_size'] == 1000000) & (results_infer['synth_model'].isin(curr_synth_models))][cols]\n",
    "\n",
    "results = results_recon.merge(results_dcr, how='inner', on=['data_name', 'synth_model', 'synth_size'], suffixes=['_recon', '_dcr'])\n",
    "results = results.merge(results_infer, how='inner', on=['data_name', 'synth_model', 'synth_size']).rename({'acc': 'acc_infer'}, axis='columns')\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_attack('recon')\n",
    "results[(results['synth_model'].apply(lambda x: '_10eps' in x or '_100eps' in x)) & (results['synth_size'].isin([1000000, 100]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = get_attack('inference')\n",
    "results[(results['synth_model'].apply(lambda x: '_10eps' in x or '_100eps' in x)) & (results['synth_size'].isin([1000000, 100]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6.6: Computational overhead\n",
    "with open(f'{data_dir}/log_time.txt', 'r') as f:\n",
    "    log_time = [line.rstrip() for line in f.readlines()]\n",
    "\n",
    "# parse log into results dictionary\n",
    "n_queriess = [10, 100, 1000, 10000, 100000]\n",
    "n_rowss = [10, 100, 1000, 10000, 100000, 1000000]\n",
    "results_dict = {\n",
    "    action: {\n",
    "        n_queries: {\n",
    "            n_rows: None \n",
    "            for n_rows in n_rowss\n",
    "        }\n",
    "        for n_queries in n_queriess\n",
    "    }\n",
    "    for action in ['gen_queries', 'process_queries', 'attack']\n",
    "}\n",
    "\n",
    "for i, curr_line in enumerate(log_time):\n",
    "    if ',' not in curr_line:\n",
    "        curr_value = float(curr_line)\n",
    "        action_line_split = log_time[i-1].split(',')\n",
    "        curr_action, n_queries = action_line_split[0], int(action_line_split[1])\n",
    "        if curr_action == 'gen_queries':\n",
    "            for n_rows in n_rowss:\n",
    "                results_dict[curr_action][n_queries][n_rows] = curr_value\n",
    "        else:\n",
    "            n_rows = int(action_line_split[2])\n",
    "            results_dict[action_line_split[0]][n_queries][n_rows] = curr_value\n",
    "\n",
    "records = []\n",
    "for i, n_rows in enumerate(n_rowss):\n",
    "    record = {'n_rows': n_rows}\n",
    "    print(f'$10^{i + 1}$ & ', end='')\n",
    "    for n_queries in n_queriess:\n",
    "        elapsed_time = results_dict['gen_queries'][n_queries][n_rows] + \\\n",
    "                    results_dict['process_queries'][n_queries][n_rows] + \\\n",
    "                    results_dict['attack'][n_queries][n_rows]\n",
    "        \n",
    "        record[n_queries] = elapsed_time / 500\n",
    "        print(f'{elapsed_time / 500:.2f} & ', end='')\n",
    "    \n",
    "        # records.append({\n",
    "        #     'n_queries': n_queries,\n",
    "        #     'n_rows': n_rows,\n",
    "        #     'amort_time': elapsed_time / 500\n",
    "        # })\n",
    "    print()\n",
    "    \n",
    "    records.append(record)\n",
    "\n",
    "results_time = pd.DataFrame.from_records(records)\n",
    "results_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Section 6.6 Memory usage\n",
    "\n",
    "with open(f'{data_dir}/memory_usage.txt', 'r') as f:\n",
    "    log_memory = np.array([float(line.rstrip()) for line in f.readlines()])\n",
    "\n",
    "amort_memory = (log_memory.max() / 32) / 1024\n",
    "print(f'Average memory cost: {amort_memory:.2f} GB/rep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Appendix B: total number of possible queries\n",
    "from itertools import combinations\n",
    "from tqdm import tqdm\n",
    "\n",
    "def get_n_queries(data_name, k):\n",
    "    secret_bit = get_default_secret_bit(data_name)\n",
    "    avg_n_queries = 0\n",
    "    reps = 500\n",
    "    for rep in tqdm(range(reps)):\n",
    "        df = pd.read_csv(f'{data_dir}/{data_name}/reps/rep_{rep}/df.csv')\n",
    "        cols_X = list(df.columns)\n",
    "        cols_X.remove(secret_bit)\n",
    "        df_matrix = df[cols_X].to_numpy()\n",
    "\n",
    "        _, m = df_matrix.shape\n",
    "\n",
    "        # gather number of unique values for each attribute\n",
    "        n_uniq_vals = []\n",
    "        for attr_ind in range(m):\n",
    "            n_uniq_vals.append(len(np.unique(df_matrix[:, attr_ind])))\n",
    "\n",
    "        n_queries = 0\n",
    "        attr_indss = combinations(range(m), k - 1)\n",
    "        for attr_inds in attr_indss:\n",
    "            curr_n_queries = 1\n",
    "            for attr_ind in attr_inds:\n",
    "                curr_n_queries *= n_uniq_vals[attr_ind]\n",
    "            \n",
    "            n_queries += curr_n_queries\n",
    "        \n",
    "        avg_n_queries += n_queries / reps\n",
    "    \n",
    "    return avg_n_queries\n",
    "\n",
    "get_n_queries('acs', 4), get_n_queries('fire', 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_privacy[(result_privacy['data_name'] == 'fire') & (result_privacy['synth_model'] == 'RAP_2Kiters') & (result_privacy['n_queries'].isin([1000, 10000, -1]) & (result_privacy['synth_size'] == 1000000))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_privacy[(result_privacy['data_name'] == 'fire') & (result_privacy['synth_model'] == 'RAP_2Kiters') & (result_privacy['n_queries'] == -1) & (result_privacy['k'] == 3) & (result_privacy['synth_size'] == 1000)]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('recon')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d972c074248e2a3f9c1b10867d3e5f259385e525e2d99480e4be6d54da507c21"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
